## 20180727

training data는 행렬

training label은 벡터. 

예측을 할 때 통계를 쓴다. 오늘 같은 경우에는 정확도를 측정하는 도구를 가져와서 쓸 것이다. 측정기법이 있다면 더 정확하게 예측할 수 있을 것이다. test label을 넣고 

clf = RandomForestClassifier()

train데이터로 점수를 계산해본다. 모델을 만드는게 얼마나 예측이 가능한지. 

train데이터 예측과 test데이터의 격차가 벌어질 수록 overfitting되는 것이다. 그 차이가 얼마나 나는지 같이 배울 것이다. unsupervised machine learning은 같이 check한다. 

예제는 기본값이 10이다. 국민청원 70%을 10개로 쪼개고 열번을 돈다. 하나는 테스트 셋, 하나는 학습셋으로 써서 평균을 낸다. 

Generalization  ; 일반적인 데이터셋에 맞게 할 것이다. 

over fitting 특정데이터에는 맞는데 조금만 바뀌어도 안되는 것. 

decision tree는 tree에 따라서 계속 가지를 뻣어나간다. under -> over되는 과정을 보여주고 최적점을 찾는다. decision tree가 여러개 모여있다. 

data frame을 두개를 만들것이다. 단어를 벡터화 할 것이다. 

데이터가 많을 수록 학습을 잘 한다. 아웃라이어가 많으면 학습을 잘못한다. 

코드를 빨리 돌려보기 위해서는 숫자를 좀 줄일 수 잇다. 



피쳐수, n그램, mean을 바꿔주는 것 만으로도 정확도 예측에 도움이 된다. scikit learn에 예측 튜토리얼이 있다. 코드가 존재함. 



정규표현식

트레이닝 랜덤샘플링

민이랑 맥스 피쳐 



아웃라이어 데이터 제거

모수 높이기



## 20180727 _ statistics



이렇게 여러 다른 분포를 가정하고 회귀분석을 하는 것을 일반화 선형 모형(Generalized Linear Model)이라고 해.  

데이터수가 많아지면 정규분포가 된다. 

확률에서 근원사건 : 일어날 수 있는 모든 사건. 

 Z : 확률변수

normsinv(확률) : z값을 뱉어라

normsdist(z) : 누적확률을 뱉어라.



평균이 c 보다 클 확률이 0.05보다 크면 충분히 크다고 한다. 이를 직접 구하기엔 어렵다. 



1종오류 : 귀무가설이 맞을 때 귀무가설을 기각하는 오류 ()

1종 오류가 더 치명적이다. 



코드과정  